{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17247e5f-18a5-4668-8424-f54bc85fc590",
   "metadata": {},
   "outputs": [],
   "source": [
    "## add in security measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f19b17-92ae-431d-9b23-a31d49940120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib3\n",
    "import ssl\n",
    "\n",
    "\n",
    "class CustomHttpAdapter (requests.adapters.HTTPAdapter):\n",
    "    # \"Transport adapter\" that allows us to use custom ssl_context.\n",
    "\n",
    "    def __init__(self, ssl_context=None, **kwargs):\n",
    "        self.ssl_context = ssl_context\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def init_poolmanager(self, connections, maxsize, block=False):\n",
    "        self.poolmanager = urllib3.poolmanager.PoolManager(\n",
    "            num_pools=connections, maxsize=maxsize,\n",
    "            block=block, ssl_context=self.ssl_context)\n",
    "\n",
    "\n",
    "def get_legacy_session():\n",
    "    ctx = ssl.create_default_context(ssl.Purpose.SERVER_AUTH)\n",
    "    ctx.check_hostname = False\n",
    "    ctx.verify_mode = ssl.CERT_NONE\n",
    "    ctx.options |= 0x4  # OP_LEGACY_SERVER_CONNECT\n",
    "    session = requests.session()\n",
    "    session.mount('https://', CustomHttpAdapter(ctx))\n",
    "    return session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8258db7b-2a18-448a-ac7a-556306a11a3f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## See Crossing Inventory Data Search for more information. [Link]('https://railroads.dot.gov/safety-data/fra-safety-data-reporting/crossing-inventory-data-search?title=&field_topic_target_id=1311')\n",
    "\n",
    "Metadata: https://railroads.dot.gov/sites/fra.dot.gov/files/fra_net/3088/datbyfld22802.pdfhttps://railroads.dot.gov/sites/fra.dot.gov/files/fra_net/3088/datbyfld22802.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34d9a8b8-51cc-4f90-a238-e00498efa443",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "import pandas\n",
    "import json\n",
    "import numpy\n",
    "import os\n",
    "import sys\n",
    "import geopandas\n",
    "import janitor\n",
    "from path import Path\n",
    "import folium\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib3\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9012b4d-4ea2-40b5-9bbe-ca7347c6520e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# path configuration\n",
    "working_directory = Path.getcwd()\n",
    "\n",
    "inputs_path = working_directory / 'inputs'\n",
    "outputs_path = working_directory / 'outputs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8dd94c1c-b17c-4b52-ae17-350927a50802",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# export function\n",
    "def to_file(callback, desired_name, extension='csv'):\n",
    "    current_files = sorted(outputs_path.files(desired_name + '*.' + extension))\n",
    "    if current_files:\n",
    "        last_file = current_files[-1]\n",
    "        os.remove(last_file)\n",
    "    final_name = '{}.{}'.format(desired_name, extension)\n",
    "    callback(outputs_path / final_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "401d019b-3a49-4fd2-bb6f-050c6360846e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the number of items to retrieve per API call\n",
    "items_per_call = 10\n",
    "\n",
    "# Initialize a variable to keep track of the current skip value\n",
    "current_skip = 0\n",
    "\n",
    "total_items_to_retrieve = 200\n",
    "\n",
    "# Create an empty list to store the data\n",
    "data_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c797fcc5-509b-4758-a806-9743bcd92af6",
   "metadata": {},
   "source": [
    "### Set up API parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0492f92f-9e20-47f9-8902-812149681943",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"https://safetydata.fra.dot.gov/MasterWebService/PublicApi/frads/v1/odata/gcis/Crossings?token=7d9f06fbf611c46d2d767ebd72742923&$format=json&$filter=StateCD eq '29'&$skip=110\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"https://safetydata.fra.dot.gov/MasterWebService/PublicApi/frads/v1/odata/gcis/Crossings?token=7d9f06fbf611c46d2d767ebd72742923&$format=json&$filter=StateCD eq '29'&$skip=110\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "30da8463-2151-499e-8fc6-d59342ade951",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"https://safetydata.fra.dot.gov/MasterWebService/PublicApi/frads/v1/odata/gcis/Crossings?&token=7d9f06fbf611c46d2d767ebd72742923&$format=json&$filter=StateCD eq '29'&$skip=110\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8001ba0b-9786-4b68-bd87-c7ba709d5eac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set up api parameters\n",
    "base_url = \"http://safetydata.fra.dot.gov/MasterWebService/PublicApi/frads/v1/odata/gcis\"\n",
    "dataset = 'Crossings'\n",
    "state_fips = \"StateCD eq '29'\"\n",
    "api_key = '7d9f06fbf611c46d2d767ebd72742923'\n",
    "\n",
    "# by agency ID\n",
    "agency = 'ReportingAgencyId eq 891'\n",
    "# by county\n",
    "county_fips = \"CntyCD eq '29037'\"\n",
    "# by railroad\n",
    "railroad = \"OperatingRailroadCode eq 'AM'\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0da8c8-4356-4c16-ac64-95d1dab46340",
   "metadata": {},
   "source": [
    "### By State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b2e956ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nanzawi\\AppData\\Local\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1061: InsecureRequestWarning: Unverified HTTPS request is being made to host 'safetydata.fra.dot.gov'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\nanzawi\\AppData\\Local\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1061: InsecureRequestWarning: Unverified HTTPS request is being made to host 'safetydata.fra.dot.gov'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\nanzawi\\AppData\\Local\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1061: InsecureRequestWarning: Unverified HTTPS request is being made to host 'safetydata.fra.dot.gov'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\nanzawi\\AppData\\Local\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1061: InsecureRequestWarning: Unverified HTTPS request is being made to host 'safetydata.fra.dot.gov'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\nanzawi\\AppData\\Local\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1061: InsecureRequestWarning: Unverified HTTPS request is being made to host 'safetydata.fra.dot.gov'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\nanzawi\\AppData\\Local\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1061: InsecureRequestWarning: Unverified HTTPS request is being made to host 'safetydata.fra.dot.gov'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "C:\\Users\\nanzawi\\AppData\\Local\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1061: InsecureRequestWarning: Unverified HTTPS request is being made to host 'safetydata.fra.dot.gov'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create a loop to make API calls until you reach the total_items_to_retrieve\n",
    "while current_skip < total_items_to_retrieve:\n",
    "    # Build the API endpoint with the current skip value\n",
    "    endpoint = f\"{base_url}/{dataset}?token={api_key}&$format=json&$filter={state_fips}&$skip={current_skip}\"\n",
    "\n",
    "    # Make the API call here\n",
    "    response = get_legacy_session().get(endpoint, verify=False)\n",
    "\n",
    "    # Check if the API call was successful\n",
    "    if response.status_code == 200:\n",
    "        # Convert the API response data to a DataFrame\n",
    "        api_data = response.json().get('value', [])  # Extract 'value' key\n",
    "        \n",
    "        # Extend the data_list with the extracted data\n",
    "        data_list.extend(api_data)\n",
    "        \n",
    "        # Increment the skip value for the next iteration\n",
    "        current_skip += items_per_call\n",
    "    else:\n",
    "        print(f\"API request failed with status code {response.status_code}\")\n",
    "        break  # Exit the loop if the API request fails\n",
    "\n",
    "# Create a DataFrame from the data_list\n",
    "df = pandas.DataFrame(data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7badaa7-4b55-4f86-84eb-9d3c23ce11fe",
   "metadata": {},
   "source": [
    "### By Reporting Agency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c6aff5-696f-4c0c-9985-e2bc92f81d87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create a loop to make API calls until you reach the total_items_to_retrieve\n",
    "while current_skip < total_items_to_retrieve:\n",
    "    # Build the API endpoint with the current skip value\n",
    "    endpoint = f\"{base_url}/{dataset}?&token={api_key}&$format=json&$filter={agency}&$skip={current_skip}\"\n",
    "    # Make the API call here\n",
    "    response = requests.get(endpoint, verify=False)\n",
    "    \n",
    "    # Check if the API call was successful\n",
    "    if response.status_code == 200:\n",
    "        # Convert the API response data to a DataFrame\n",
    "        api_data = response.json().get('value', [])  # Extract 'value' key\n",
    "        \n",
    "        # Extend the data_list with the extracted data\n",
    "        data_list.extend(api_data)\n",
    "        \n",
    "        # Increment the skip value for the next iteration\n",
    "        current_skip += items_per_call\n",
    "    else:\n",
    "        print(f\"API request failed with status code {response.status_code}\")\n",
    "        break  # Exit the loop if the API request fails\n",
    "\n",
    "# Create a DataFrame from the data_list\n",
    "df = pandas.DataFrame(data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8cf0f2-1053-4341-99b7-b4154f07b89f",
   "metadata": {},
   "source": [
    "### By county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bf9a0f-1baf-4573-a0aa-4a5fc67f0815",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a loop to make API calls until you reach the total_items_to_retrieve\n",
    "while current_skip < total_items_to_retrieve:\n",
    "    # Build the API endpoint with the current skip value\n",
    "    endpoint = f\"{base_url}/{dataset}?&token={api_key}&$format=json&$filter={county_fips}&$skip={current_skip}\"\n",
    "\n",
    "    # Make the API call here\n",
    "    response = requests.get(endpoint)\n",
    "    \n",
    "    # Check if the API call was successful\n",
    "    if response.status_code == 200:\n",
    "        # Convert the API response data to a DataFrame\n",
    "        api_data = response.json().get('value', [])  # Extract 'value' key\n",
    "        \n",
    "        # Extend the data_list with the extracted data\n",
    "        data_list.extend(api_data)\n",
    "        \n",
    "        # Increment the skip value for the next iteration\n",
    "        current_skip += items_per_call\n",
    "    else:\n",
    "        print(f\"API request failed with status code {response.status_code}\")\n",
    "        break  # Exit the loop if the API request fails\n",
    "\n",
    "# Create a DataFrame from the data_list\n",
    "df = pandas.DataFrame(data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c040d6-7e05-4d88-9072-03f5c66cfb04",
   "metadata": {
    "tags": []
   },
   "source": [
    "### By Railroad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c196a617-1eae-498a-a517-6813a400137d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a loop to make API calls until you reach the total_items_to_retrieve\n",
    "while current_skip < total_items_to_retrieve:\n",
    "    # Build the API endpoint with the current skip value\n",
    "    endpoint = f\"{base_url}/{dataset}?&token={api_key}&$format=json&$filter={railroad}&$skip={current_skip}\"\n",
    "\n",
    "    # Make the API call here\n",
    "    response = requests.get(endpoint)\n",
    "    \n",
    "    # Check if the API call was successful\n",
    "    if response.status_code == 200:\n",
    "        # Convert the API response data to a DataFrame\n",
    "        api_data = response.json().get('value', [])  # Extract 'value' key\n",
    "        \n",
    "        # Extend the data_list with the extracted data\n",
    "        data_list.extend(api_data)\n",
    "        \n",
    "        # Increment the skip value for the next iteration\n",
    "        current_skip += items_per_call\n",
    "    else:\n",
    "        print(f\"API request failed with status code {response.status_code}\")\n",
    "        break  # Exit the loop if the API request fails\n",
    "\n",
    "# Create a DataFrame from the data_list\n",
    "df = pandas.DataFrame(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b925a021-0c6a-4083-8846-57cbc0a98abd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# drop any instance null values from df return for Latitude OR Lnogitude\n",
    "df = df[~df.Latitude.isna() | ~df.Longitude.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30463f3-85f8-4217-9974-ca4fd9259cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    " my_geoseries.set_crs(epsg=4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e248d0e0-be9e-4cd3-a437-ce95ce52a3e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#make points spatial\n",
    "crs=\"EPSG:4326\"\n",
    "\n",
    "points = geopandas.GeoDataFrame(\n",
    "    df, crs=crs, geometry=geopandas.points_from_xy(df.Longitude, df.Latitude)\n",
    ")\n",
    "\n",
    "# make points float data type\n",
    "points[['Latitude','Longitude']] = points[['Latitude','Longitude']].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020504cb-fdef-4cca-a29d-5201ac5c7bfb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# narrow down to zone_points-  290376360 is pleasant hill, 290377600 is stratsburg\n",
    "zone_points = points[points.CityCD.str.contains('290376360|290377600')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6574ba-45f2-4d98-9d35-eab50d4ee89f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%store zone_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fb6088-4033-4fe7-9fe5-efac36530947",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Latitude and Longitude coordinates for Missouri\n",
    "missouri_coordinates = [38.573936, -92.603760]\n",
    "\n",
    "# Create a Folium map centered around Missouri\n",
    "m = folium.Map(location=missouri_coordinates, zoom_start=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba330dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "folium.Map(location=geopandas.GeoDataFrame(amtrack_routes.geometry + zone_points.geometry), zoom_start=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3d7e05-9ecf-4f70-bf08-aca502749d20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read in amtrack routes\n",
    "amtrack_routes = geopandas.read_file(inputs_path/'Amtrak_Routes.geojson')\n",
    "\n",
    "amtrack_routes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d848470",
   "metadata": {},
   "outputs": [],
   "source": [
    "amtrack_routes.geometry.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb150e1-d757-4aa6-98d5-f127115339c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amtrack_routes.NAME.unique()\n",
    "\n",
    "# filter for particular route and set crs\n",
    "filtered_routes = amtrack_routes[amtrack_routes.NAME == 'Kansas City - St. Louis (Missouri River Runner)']\n",
    "filtered_routes = filtered_routes.set_crs(4326, allow_override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e2da9c-560b-4d1d-b721-a35e17bc79a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# filtered points\n",
    "filtered_routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ab18e0-4053-4557-882c-9357df2ec151",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filtered_routes.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf88149-adfc-449d-96eb-f4617d61a8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = folium.Map(location=[your_initial_latitude, your_initial_longitude], zoom_start=your_initial_zoom)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdee029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the GeoDataFrame and add markers for points\n",
    "for idx, row in zone_points.iterrows():\n",
    "    # Get the coordinates of the point\n",
    "    lon, lat = row.geometry.coords[0]\n",
    "    # Create a marker for each point and add it to the map\n",
    "    folium.Marker([lat, lon],icon=folium.Icon(icon=\"cloud\")).add_to(m)\n",
    "\n",
    "# Iterate through the GeoDataFrame and add PolyLines for each LineString geometry\n",
    "for idx, row in filtered_routes.iterrows():\n",
    "    # Extract the geometry\n",
    "    geometry = row.geometry\n",
    "\n",
    "    # Check if it's a MultiLineString\n",
    "    if geometry.geom_type == 'MultiLineString':\n",
    "        for line_string in geometry:\n",
    "            # Convert each LineString to a list of coordinate pairs\n",
    "            coordinates = list(line_string.coords)\n",
    "            \n",
    "            # Create a PolyLine using the coordinates and add it to the map\n",
    "            folium.PolyLine(locations=coordinates, color='blue').add_to(m)\n",
    "    elif geometry.geom_type == 'LineString':\n",
    "        # Convert the LineString to a list of coordinate pairs\n",
    "        coordinates = list(geometry.coords)\n",
    "\n",
    "        # Create a PolyLine using the coordinates and add it to the map\n",
    "        folium.PolyLine(locations=coordinates, color='blue').add_to(m)\n",
    "        \n",
    "# Save the map to an HTML file or display it in a Jupyter Notebook\n",
    "m.save(\"map.html\")\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a6894f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a GeoDataFrame called \"points\" with a \"geometry\" column containing Point geometries\n",
    "for idx, row in zone_points.iterrows():\n",
    "    # Get the coordinates of the point\n",
    "    lon, lat = row.geometry.coords[0]\n",
    "    # Create a marker for each point and add it to the map\n",
    "    folium.Marker([lat, lon],icon=folium.Icon(icon=\"cloud\")).add_to(m)\n",
    "    \n",
    "# Save the map to an HTML file or display it in a Jupyter Notebook\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7723989-5d59-4877-8748-e2d5c962d229",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "callback = lambda p: filtered_routes.to_file(p, driver='ESRI Shapefile')\n",
    "to_file(callback, 'MoDOT_XX_Amtrak_Route', 'shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0278e6d2-d21e-47f1-8031-d408639e20ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "callback = lambda p: zone_points.to_file(p, driver='ESRI Shapefile')\n",
    "to_file(callback, 'MoDOT_XX_Amtrak_Points', 'shp')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
